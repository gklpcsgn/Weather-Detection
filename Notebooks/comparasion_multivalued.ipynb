{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ensemble model python file\n",
    "from EnsembleModel import EnsembleModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from Preprocessing import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use preprocess function to get train and test data\n",
    "X_train, X_test, y_train, y_test, X_val, y_val = preprocess(pd.read_csv('austin_weather.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8282828282828283\n",
      "Weighted Precision =  0.8000604047115676\n",
      "Weighted Recall =  0.6233766233766234\n",
      "Weighted F1 score =  0.6912999479346175\n"
     ]
    }
   ],
   "source": [
    "# using classifier chains\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression# initialize classifier chains multi-label classifier\n",
    "classifier = ClassifierChain(LogisticRegression())# Training logistic regression model on train data\n",
    "classifier.fit(X_train, y_train)# predict\n",
    "predictions = classifier.predict(X_test)# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy = \",accuracy_score(y_test,predictions))\n",
    "\n",
    "#calculate weighted accuracy, precision, recall, f1 score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print(\"Weighted Precision = \",precision_score(y_test, predictions, average=\"weighted\"))\n",
    "print(\"Weighted Recall = \",recall_score(y_test, predictions, average=\"weighted\"))\n",
    "print(\"Weighted F1 score = \",f1_score(y_test, predictions, average=\"weighted\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8282828282828283\n",
      "Weighted Precision =  0.8000604047115676\n",
      "Weighted Recall =  0.6233766233766234\n",
      "Weighted F1 score =  0.6912999479346175\n"
     ]
    }
   ],
   "source": [
    "# using binary relevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# initialize binary relevance multi-label classifier\n",
    "# with a logistic regression base classifier\n",
    "classifier = ClassifierChain(LogisticRegression())\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(y_test,predictions))\n",
    "#calculate weighted accuracy, precision, recall, f1 score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print(\"Weighted Precision = \",precision_score(y_test, predictions, average=\"weighted\"))\n",
    "print(\"Weighted Recall = \",recall_score(y_test, predictions, average=\"weighted\"))\n",
    "print(\"Weighted F1 score = \",f1_score(y_test, predictions, average=\"weighted\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8282828282828283\n",
      "Weighted Precision =  0.8057513914656772\n",
      "Weighted Recall =  0.6363636363636364\n",
      "Weighted F1 score =  0.7088205911735325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/berkay/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# using label powerset\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# initialize label powerset multi-label classifier\n",
    "# with logistic regression base classifier\n",
    "classifier = LabelPowerset(LogisticRegression())# train\n",
    "classifier.fit(X_train, y_train)# predict\n",
    "predictions = classifier.predict(X_test)# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(y_test,predictions))\n",
    "#calculate weighted accuracy, precision, recall, f1 score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print(\"Weighted Precision = \",precision_score(y_test, predictions, average=\"weighted\"))\n",
    "print(\"Weighted Recall = \",recall_score(y_test, predictions, average=\"weighted\"))\n",
    "print(\"Weighted F1 score = \",f1_score(y_test, predictions, average=\"weighted\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.42424242424242425\n",
      "Weighted Precision =  0.7295010252904989\n",
      "Weighted Recall =  0.7922077922077922\n",
      "Weighted F1 score =  0.677056277056277\n"
     ]
    }
   ],
   "source": [
    "# using binary relevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = BinaryRelevance(GaussianNB())# train\n",
    "classifier.fit(X_train, y_train)# predict\n",
    "predictions = classifier.predict(X_test)# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(y_test,predictions))\n",
    "#calculate weighted accuracy, precision, recall, f1 score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print(\"Weighted Precision = \",precision_score(y_test, predictions, average=\"weighted\"))\n",
    "print(\"Weighted Recall = \",recall_score(y_test, predictions, average=\"weighted\"))\n",
    "print(\"Weighted F1 score = \",f1_score(y_test, predictions, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/berkay/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.7777777777777778\n",
      "Weighted Precision =  0.6461321287408244\n",
      "Weighted Recall =  0.6103896103896104\n",
      "Weighted F1 score =  0.6269204479730796\n"
     ]
    }
   ],
   "source": [
    "# using adapted algorithm\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "# initialize mlknn multi-label classifier\n",
    "# with k=10\n",
    "X_train_csr = lil_matrix(X_train).toarray()\n",
    "y_train_csr = lil_matrix(y_train).toarray()\n",
    "X_test_csr = lil_matrix(X_test).toarray()\n",
    "classifier_new = MLkNN(k=10)# train\n",
    "classifier_new.fit(X=X_train_csr, y=y_train_csr)# predict\n",
    "predictions = classifier_new.predict(X_test_csr)# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(y_test,predictions))\n",
    "#calculate weighted accuracy, precision, recall, f1 score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print(\"Weighted Precision = \",precision_score(y_test, predictions, average=\"weighted\"))\n",
    "print(\"Weighted Recall = \",recall_score(y_test, predictions, average=\"weighted\"))\n",
    "print(\"Weighted F1 score = \",f1_score(y_test, predictions, average=\"weighted\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '_ascontainer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m csr_matrix, lil_matrix\n\u001b[1;32m      9\u001b[0m \u001b[39m# initialize RakelD multi-label classifier\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# with a gaussian naive bayes base classifier\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m#convert to dense\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m#scipy.sparse.csr_matrix(X_train.values)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m X_train_csr \u001b[39m=\u001b[39m csr_matrix\u001b[39m.\u001b[39;49mtodense(X_train)\n\u001b[1;32m     14\u001b[0m y_train_csr \u001b[39m=\u001b[39m csr_matrix\u001b[39m.\u001b[39mtodense(y_train)\n\u001b[1;32m     15\u001b[0m X_test_csr \u001b[39m=\u001b[39m csr_matrix\u001b[39m.\u001b[39mtodense(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_base.py:946\u001b[0m, in \u001b[0;36mspmatrix.todense\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtodense\u001b[39m(\u001b[39mself\u001b[39m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    917\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[39m    Return a dense matrix representation of this matrix.\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[39m        `numpy.matrix` object that shares the same memory.\u001b[39;00m\n\u001b[1;32m    945\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 946\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ascontainer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoarray(order\u001b[39m=\u001b[39morder, out\u001b[39m=\u001b[39mout))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:5907\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5900\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5901\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5902\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5903\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5904\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5905\u001b[0m ):\n\u001b[1;32m   5906\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5907\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '_ascontainer'"
     ]
    }
   ],
   "source": [
    "#use ensemble classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skmultilearn.ensemble import RakelD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "# initialize RakelD multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "#convert to dense\n",
    "#scipy.sparse.csr_matrix(X_train.values)\n",
    "X_train_csr = csr_matrix.todense(X_train)\n",
    "y_train_csr = csr_matrix.todense(y_train)\n",
    "X_test_csr = csr_matrix.todense(X_test)\n",
    "\n",
    "classifier = RakelD(\n",
    "    base_classifier=GaussianNB(),\n",
    "    base_classifier_require_dense=[False, True],\n",
    "    labelset_size=2\n",
    ")\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train_csr, y_train_csr)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test_csr)\n",
    "\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(y_test,predictions))\n",
    "\n",
    "#calculate weighted accuracy, precision, recall, f1 score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print(\"Weighted Precision = \",precision_score(y_test, predictions, average=\"weighted\"))\n",
    "print(\"Weighted Recall = \",recall_score(y_test, predictions, average=\"weighted\"))\n",
    "print(\"Weighted F1 score = \",f1_score(y_test, predictions, average=\"weighted\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 22\u001b[0m\n\u001b[1;32m     15\u001b[0m classifier \u001b[39m=\u001b[39m RakelO(\n\u001b[1;32m     16\u001b[0m     base_classifier\u001b[39m=\u001b[39mGaussianNB(),\n\u001b[1;32m     17\u001b[0m     base_classifier_require_dense\u001b[39m=\u001b[39m[\u001b[39mFalse\u001b[39;00m, \u001b[39mTrue\u001b[39;00m],\n\u001b[1;32m     18\u001b[0m     labelset_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m classifier\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     24\u001b[0m \u001b[39m# predict\u001b[39;00m\n\u001b[1;32m     25\u001b[0m predictions \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skmultilearn/ensemble/rakelo.py:121\u001b[0m, in \u001b[0;36mRakelO.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39m\"\"\"Fits classifier to training data\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \n\u001b[1;32m     97\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39m    fitted instance of self\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier \u001b[39m=\u001b[39m MajorityVotingClassifier(\n\u001b[1;32m    110\u001b[0m     classifier\u001b[39m=\u001b[39mLabelPowerset(\n\u001b[1;32m    111\u001b[0m         classifier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_classifier,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m     require_dense\u001b[39m=\u001b[39m[\u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m]\n\u001b[1;32m    120\u001b[0m )\n\u001b[0;32m--> 121\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclassifier\u001b[39m.\u001b[39;49mfit(X, y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skmultilearn/problem_transform/br.py:153\u001b[0m, in \u001b[0;36mBinaryRelevance.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    149\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_output_format(\n\u001b[1;32m    150\u001b[0m     y, sparse_format\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m'\u001b[39m, enforce_sparse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifiers_ \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 153\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_partition(X, y)\n\u001b[1;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_label_count \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m    156\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_count_):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skmultilearn/ensemble/partition.py:140\u001b[0m, in \u001b[0;36mLabelSpacePartitioningClassifier._generate_partition\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_partition\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m    120\u001b[0m     \u001b[39m\"\"\"Cluster the label space\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \n\u001b[1;32m    122\u001b[0m \u001b[39m    Saves the partiton generated by the clusterer to :code:`self.partition_` and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39m        returns an instance of itself\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpartition_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclusterer\u001b[39m.\u001b[39;49mfit_predict(X, y)\n\u001b[1;32m    141\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_count_ \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpartition_)\n\u001b[1;32m    142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_label_count \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skmultilearn/cluster/random.py:94\u001b[0m, in \u001b[0;36mRandomLabelSpaceClusterer.fit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_predict\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m     80\u001b[0m     \u001b[39m\"\"\"Cluster the output space\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[1;32m     82\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39m        label space division, each sublist represents labels that are in that community\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcluster_count\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_size \u001b[39m<\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[1;32m     95\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot include all of \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m labels in \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m clusters of \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m labels\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     96\u001b[0m             y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],\n\u001b[1;32m     97\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_count,\n\u001b[1;32m     98\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_size\n\u001b[1;32m     99\u001b[0m         ))\n\u001b[1;32m    101\u001b[0m     all_labels_assigned_to_division \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skmultilearn.ensemble import RakelO\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "# initialize RakelD multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "#convert to dense\n",
    "X_train_csr = lil_matrix(X_train).toarray()\n",
    "y_train_csr = lil_matrix(y_train).toarray()\n",
    "X_test_csr = lil_matrix(X_test).toarray()\n",
    "\n",
    "classifier = RakelO(\n",
    "    base_classifier=GaussianNB(),\n",
    "    base_classifier_require_dense=[False, True],\n",
    "    labelset_size=2\n",
    ")\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(y_test,predictions))\n",
    "\n",
    "#calculate weighted accuracy, precision, recall, f1 score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print(\"Weighted Precision = \",precision_score(y_test, predictions, average=\"weighted\"))\n",
    "print(\"Weighted Recall = \",recall_score(y_test, predictions, average=\"weighted\"))\n",
    "print(\"Weighted F1 score = \",f1_score(y_test, predictions, average=\"weighted\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 17:51:21.431233: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-16 17:51:21.431278: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEKA 1.9.2 not found, downloading\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.ext import Meka, download_meka\n",
    "\n",
    "# download meka\n",
    "download_meka()\n",
    "\n",
    "# initialize meka\n",
    "meka_classifier = Meka(\n",
    "    meka_classifier = \"meka.classifiers.multilabel.LC\",\n",
    "    weka_classifier = \"weka.classifiers.bayes.NaiveBayes\",\n",
    "    meka_classpath = download_meka(),\n",
    "    java_classpath = \"/usr/local/lib/python3.6/dist-packages/meka/lib/meka.jar\",\n",
    ")\n",
    "\n",
    "\n",
    "meka_classifier.fit(X_train, y_train)\n",
    "predictions = meka_classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
